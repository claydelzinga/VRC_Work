#gonna try and web scrape 
#originally needed to pull specific data from a website to put into an excel sheet
library(httr)
library(rvest)
library(tidyr)
library(dplyr)

# Function to extract data from a URL
extract_data <- function(url) {
  response <- httr::GET(url)
  page_html <- read_html(content(response, "text"))
  
  growth <- page_html %>% 
    html_nodes("#jumpLinkHere > div > div > div > div > div.specs.col-md-6.col-sm-12.col-xs-12 > div.treeCharacter > p:nth-child(9)") %>% 
    html_text() %>%
    trimws() 
  
  native_o <- page_html %>% 
    html_nodes("#jumpLinkHere > div > div > div > div > div.specs.col-md-6.col-sm-12.col-xs-12 > div.plantSite > p:nth-child(5)") %>% 
    html_text() %>%
    trimws() 
  
  native_na <- page_html %>% 
    html_nodes("#jumpLinkHere > div > div > div > div > div.specs.col-md-6.col-sm-12.col-xs-12 > div.plantSite > p:nth-child(7)") %>% 
    html_text() %>%
    trimws() 
  
  insect_diseases <- page_html %>% 
    html_nodes("#jumpLinkHere > div > div > div > div > div.right.col-md-6.col-sm-12.col-xs-12 > div.insAndDes > p") %>% 
    html_text() %>%
    trimws() 
  
  management <- page_html %>% 
    html_nodes("#jumpLinkHere > div > div > div > div > div.right.col-md-6.col-sm-12.col-xs-12 > div.manageNotes > p") %>% 
    html_text() %>%
    trimws() 
  
  management_backup <- page_html %>% 
    html_nodes("#jumpLinkHere > div > div > div > div > div.right.col-md-6.col-sm-12.col-xs-12 > div.manageNotes > ul") %>% 
    html_text() %>%
    trimws() 
  
  planting_site <- page_html %>% 
    html_nodes("#jumpLinkHere > div > div > div > div > div.specs.col-md-6.col-sm-12.col-xs-12 > div.plantSite > p.plantingSiteNames.characteristic") %>% 
    html_text() %>%
    trimws() 
  
  data <- data.frame(growth = growth,
                     native_o = ifelse(length(native_o) > 0, native_o, NA),
                     native_na = ifelse(length(native_na) > 0, native_na, NA),
                     insect_diseases = ifelse(length(insect_diseases) > 0, insect_diseases, NA),
                     management = ifelse(length(management) > 0, management, NA),
                     management_backup = ifelse(length(management_backup) > 0, management_backup, NA),
                     planting_site = ifelse(length(planting_site) > 0, planting_site, NA))
  
  return(data)
}

# List data frames
data_list <- list()

# Extract data for each URL
for (url in secondary_urls) {
  data_list[[url]] <- extract_data(url)
}

# Combine data frames into a single data frame
combined_data <- do.call(rbind, data_list)

#Clean up 
combined_data_remove <- combined_data %>%
  mutate_all(~ifelse(. == "NA", NA, .)) %>%
  mutate_all(~ifelse(is.na(.), "", .))

combined_data_remove = unite(combined_data_remove, mgmt, c(management, management_backup))
View(combined_data_remove)
